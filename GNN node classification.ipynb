{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n"
     ]
    }
   ],
   "source": [
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "def load_data(path, dataset=\"cora\"):\n",
    "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
    "    print('Loading {} dataset...'.format(dataset))\n",
    "\n",
    "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n",
    "                                        dtype=np.dtype(str))\n",
    "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32) \n",
    "    labels = encode_onehot(idx_features_labels[:, -1]) \n",
    "\n",
    "    # build graph\n",
    "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
    "    idx_map = {j: i for i, j in enumerate(idx)}\n",
    "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
    "                                    dtype=np.int32)\n",
    "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(labels.shape[0], labels.shape[0]),\n",
    "                        dtype=np.float32)\n",
    "\n",
    "    # build symmetric adjacency matrix\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "    features = normalize(features)\n",
    "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
    "\n",
    "    idx_train = range(140)\n",
    "    idx_val = range(200, 500)\n",
    "    idx_test = range(500, 1500)\n",
    "\n",
    "    features = torch.FloatTensor(np.array(features.todense()))\n",
    "    labels = torch.LongTensor(np.where(labels)[1])\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "\n",
    "    idx_train = torch.LongTensor(idx_train)\n",
    "    idx_val = torch.LongTensor(idx_val)\n",
    "    idx_test = torch.LongTensor(idx_test)\n",
    "\n",
    "    return adj, features, labels, idx_train, idx_val, idx_test\n",
    "\n",
    "adj, features, labels, idx_train, idx_val, idx_test=load_data(path=\"./cora/\", dataset=\"cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[   0,    8,   14,  ..., 1389, 2344, 2707],\n",
      "                       [   0,    0,    0,  ..., 2707, 2707, 2707]]),\n",
      "       values=tensor([0.1667, 0.1667, 0.0500,  ..., 0.2000, 0.5000, 0.2500]),\n",
      "       size=(2708, 2708), nnz=13264, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "print(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1423</th>\n",
       "      <th>1424</th>\n",
       "      <th>1425</th>\n",
       "      <th>1426</th>\n",
       "      <th>1427</th>\n",
       "      <th>1428</th>\n",
       "      <th>1429</th>\n",
       "      <th>1430</th>\n",
       "      <th>1431</th>\n",
       "      <th>1432</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2708 rows × 1433 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3         4     5     6     7     8     9     ...  \\\n",
       "0      0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1      0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2      0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3      0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4      0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "...    ...   ...   ...   ...       ...   ...   ...   ...   ...   ...  ...   \n",
       "2703   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2704   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2705   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2706   0.0   0.0   0.0   0.0  0.052632   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2707   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "          1423  1424      1425  1426  1427  1428  1429  1430  1431  1432  \n",
       "0     0.000000   0.0  0.000000  0.05   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1     0.000000   0.0  0.058824  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2     0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3     0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4     0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...        ...   ...       ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2703  0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2704  0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2705  0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2706  0.052632   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2707  0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[2708 rows x 1433 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features=pd.DataFrame(features.numpy())\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.expanduser(\"./cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"w_{}\".format(ii) for ii in range(1433)]\n",
    "column_names =  feature_names + [\"subject\"]\n",
    "node_data = pd.read_csv(os.path.join(data_dir, \"cora.content\"), sep='\\t', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_0</th>\n",
       "      <th>w_1</th>\n",
       "      <th>w_2</th>\n",
       "      <th>w_3</th>\n",
       "      <th>w_4</th>\n",
       "      <th>w_5</th>\n",
       "      <th>w_6</th>\n",
       "      <th>w_7</th>\n",
       "      <th>w_8</th>\n",
       "      <th>w_9</th>\n",
       "      <th>...</th>\n",
       "      <th>w_1424</th>\n",
       "      <th>w_1425</th>\n",
       "      <th>w_1426</th>\n",
       "      <th>w_1427</th>\n",
       "      <th>w_1428</th>\n",
       "      <th>w_1429</th>\n",
       "      <th>w_1430</th>\n",
       "      <th>w_1431</th>\n",
       "      <th>w_1432</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31336</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061127</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rule_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106406</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126012</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107140</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102850</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106418</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123188</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109323</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217139</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Case_Based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31353</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32083</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126029</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118017</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49482</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 1434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         w_0  w_1  w_2  w_3  w_4  w_5  w_6  w_7  w_8  w_9  ...  w_1424  \\\n",
       "31336      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1061127    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1106406    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "13195      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "37879      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1126012    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1107140    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1102850    0    0    0    1    0    0    0    0    0    0  ...       0   \n",
       "31349      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1106418    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1123188    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1128990    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "109323     0    0    1    0    0    0    0    0    0    0  ...       0   \n",
       "217139     0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "31353      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "32083      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1126029    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1118017    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "49482      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "753265     0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "\n",
       "         w_1425  w_1426  w_1427  w_1428  w_1429  w_1430  w_1431  w_1432  \\\n",
       "31336         0       1       0       0       0       0       0       0   \n",
       "1061127       1       0       0       0       0       0       0       0   \n",
       "1106406       0       0       0       0       0       0       0       0   \n",
       "13195         0       0       0       0       0       0       0       0   \n",
       "37879         0       0       0       0       0       0       0       0   \n",
       "1126012       0       1       0       0       0       0       0       0   \n",
       "1107140       0       0       0       0       0       0       0       0   \n",
       "1102850       0       0       0       0       0       0       0       0   \n",
       "31349         0       0       0       0       0       0       0       0   \n",
       "1106418       0       0       0       0       0       0       0       0   \n",
       "1123188       0       0       0       0       0       0       0       0   \n",
       "1128990       0       1       0       0       0       0       0       0   \n",
       "109323        0       0       0       0       0       0       0       0   \n",
       "217139        0       0       0       0       0       0       0       0   \n",
       "31353         0       0       0       0       0       0       0       0   \n",
       "32083         0       0       0       0       0       0       0       0   \n",
       "1126029       0       0       0       0       0       0       0       0   \n",
       "1118017       0       0       0       0       0       0       0       0   \n",
       "49482         0       0       0       0       0       0       0       0   \n",
       "753265        0       0       0       0       0       0       0       0   \n",
       "\n",
       "                        subject  \n",
       "31336           Neural_Networks  \n",
       "1061127           Rule_Learning  \n",
       "1106406  Reinforcement_Learning  \n",
       "13195    Reinforcement_Learning  \n",
       "37879     Probabilistic_Methods  \n",
       "1126012   Probabilistic_Methods  \n",
       "1107140                  Theory  \n",
       "1102850         Neural_Networks  \n",
       "31349           Neural_Networks  \n",
       "1106418                  Theory  \n",
       "1123188         Neural_Networks  \n",
       "1128990      Genetic_Algorithms  \n",
       "109323    Probabilistic_Methods  \n",
       "217139               Case_Based  \n",
       "31353           Neural_Networks  \n",
       "32083           Neural_Networks  \n",
       "1126029  Reinforcement_Learning  \n",
       "1118017         Neural_Networks  \n",
       "49482           Neural_Networks  \n",
       "753265          Neural_Networks  \n",
       "\n",
       "[20 rows x 1434 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      0\n",
       "1      1\n",
       "2      2\n",
       "3      3\n",
       "4      4\n",
       "..   ...\n",
       "135  135\n",
       "136  136\n",
       "137  137\n",
       "138  138\n",
       "139  139\n",
       "\n",
       "[140 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idx_train=pd.DataFrame(idx_train.numpy())\n",
    "df_idx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0    200\n",
       "1    201\n",
       "2    202\n",
       "3    203\n",
       "4    204\n",
       "..   ...\n",
       "295  495\n",
       "296  496\n",
       "297  497\n",
       "298  498\n",
       "299  499\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idx_val=pd.DataFrame(idx_val.numpy())\n",
    "df_idx_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0     500\n",
       "1     501\n",
       "2     502\n",
       "3     503\n",
       "4     504\n",
       "..    ...\n",
       "995  1495\n",
       "996  1496\n",
       "997  1497\n",
       "998  1498\n",
       "999  1499\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idx_test=pd.DataFrame(idx_test.numpy())\n",
    "df_idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GCNN import NodeClassificationGCNN\n",
    "\n",
    "model = NodeClassificationGCNN(features.shape[1], 256, np.max(labels.detach().numpy())+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out,label):\n",
    "    oneHotCodded = out.max(1)[1].type_as(label)\n",
    "    return oneHotCodded.eq(label).double().sum()/len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0 ; accuracy: 0.12857142857142856; loss: 1.9454790353775024\n",
      "Validation epoch 0 ; accuracy: 0.44666666666666666; loss: 1.8964742422103882\n",
      "Training epoch 1 ; accuracy: 0.5071428571428571; loss: 1.8837461471557617\n",
      "Validation epoch 1 ; accuracy: 0.5066666666666667; loss: 1.8363944292068481\n",
      "Training epoch 2 ; accuracy: 0.6071428571428571; loss: 1.806196928024292\n",
      "Validation epoch 2 ; accuracy: 0.5633333333333334; loss: 1.7653584480285645\n",
      "Training epoch 3 ; accuracy: 0.6642857142857143; loss: 1.712522268295288\n",
      "Validation epoch 3 ; accuracy: 0.6133333333333333; loss: 1.6887750625610352\n",
      "Training epoch 4 ; accuracy: 0.6928571428571428; loss: 1.6144105195999146\n",
      "Validation epoch 4 ; accuracy: 0.6433333333333333; loss: 1.6077704429626465\n",
      "Training epoch 5 ; accuracy: 0.7214285714285714; loss: 1.5084567070007324\n",
      "Validation epoch 5 ; accuracy: 0.6633333333333333; loss: 1.5247526168823242\n",
      "Training epoch 6 ; accuracy: 0.7285714285714285; loss: 1.403595209121704\n",
      "Validation epoch 6 ; accuracy: 0.6866666666666666; loss: 1.4407894611358643\n",
      "Training epoch 7 ; accuracy: 0.7642857142857142; loss: 1.293647050857544\n",
      "Validation epoch 7 ; accuracy: 0.69; loss: 1.3561146259307861\n",
      "Training epoch 8 ; accuracy: 0.7857142857142857; loss: 1.1797621250152588\n",
      "Validation epoch 8 ; accuracy: 0.7066666666666667; loss: 1.2744600772857666\n",
      "Training epoch 9 ; accuracy: 0.8071428571428572; loss: 1.0742417573928833\n",
      "Validation epoch 9 ; accuracy: 0.7266666666666667; loss: 1.1957528591156006\n",
      "Training epoch 10 ; accuracy: 0.8214285714285714; loss: 0.969242513179779\n",
      "Validation epoch 10 ; accuracy: 0.7433333333333333; loss: 1.1206759214401245\n",
      "Training epoch 11 ; accuracy: 0.8357142857142857; loss: 0.8789690136909485\n",
      "Validation epoch 11 ; accuracy: 0.7466666666666667; loss: 1.0490789413452148\n",
      "Training epoch 12 ; accuracy: 0.8357142857142857; loss: 0.792298436164856\n",
      "Validation epoch 12 ; accuracy: 0.7666666666666667; loss: 0.9804696440696716\n",
      "Training epoch 13 ; accuracy: 0.8642857142857143; loss: 0.7074607610702515\n",
      "Validation epoch 13 ; accuracy: 0.7933333333333333; loss: 0.9164991974830627\n",
      "Training epoch 14 ; accuracy: 0.9142857142857143; loss: 0.6234161853790283\n",
      "Validation epoch 14 ; accuracy: 0.81; loss: 0.8581538796424866\n",
      "Training epoch 15 ; accuracy: 0.9285714285714286; loss: 0.5476559996604919\n",
      "Validation epoch 15 ; accuracy: 0.8266666666666667; loss: 0.8058878779411316\n",
      "Training epoch 16 ; accuracy: 0.95; loss: 0.4836273789405823\n",
      "Validation epoch 16 ; accuracy: 0.83; loss: 0.7605231404304504\n",
      "Training epoch 17 ; accuracy: 0.9428571428571428; loss: 0.41686269640922546\n",
      "Validation epoch 17 ; accuracy: 0.83; loss: 0.722718358039856\n",
      "Training epoch 18 ; accuracy: 0.95; loss: 0.37018299102783203\n",
      "Validation epoch 18 ; accuracy: 0.8266666666666667; loss: 0.6922012567520142\n",
      "Training epoch 19 ; accuracy: 0.9714285714285714; loss: 0.31342971324920654\n",
      "Validation epoch 19 ; accuracy: 0.8166666666666667; loss: 0.668516218662262\n",
      "Training epoch 20 ; accuracy: 0.9642857142857143; loss: 0.2820907533168793\n",
      "Validation epoch 20 ; accuracy: 0.82; loss: 0.6502766609191895\n",
      "Training epoch 21 ; accuracy: 0.9714285714285714; loss: 0.24231640994548798\n",
      "Validation epoch 21 ; accuracy: 0.8133333333333334; loss: 0.6361890435218811\n",
      "Training epoch 22 ; accuracy: 0.9714285714285714; loss: 0.2130468338727951\n",
      "Validation epoch 22 ; accuracy: 0.8166666666666667; loss: 0.6251744627952576\n",
      "Training epoch 23 ; accuracy: 0.9714285714285714; loss: 0.1908762902021408\n",
      "Validation epoch 23 ; accuracy: 0.81; loss: 0.6162192821502686\n",
      "Training epoch 24 ; accuracy: 0.9714285714285714; loss: 0.16844847798347473\n",
      "Validation epoch 24 ; accuracy: 0.8066666666666666; loss: 0.6092147827148438\n",
      "Training epoch 25 ; accuracy: 0.9714285714285714; loss: 0.146004319190979\n",
      "Validation epoch 25 ; accuracy: 0.8066666666666666; loss: 0.6041961908340454\n",
      "Training epoch 26 ; accuracy: 0.9785714285714285; loss: 0.1293514370918274\n",
      "Validation epoch 26 ; accuracy: 0.8066666666666666; loss: 0.6012897491455078\n",
      "Training epoch 27 ; accuracy: 0.9857142857142858; loss: 0.11481603980064392\n",
      "Validation epoch 27 ; accuracy: 0.8066666666666666; loss: 0.6008028984069824\n",
      "Training epoch 28 ; accuracy: 0.9857142857142858; loss: 0.10182543098926544\n",
      "Validation epoch 28 ; accuracy: 0.8066666666666666; loss: 0.6028248071670532\n",
      "Training epoch 29 ; accuracy: 0.9857142857142858; loss: 0.09268244355916977\n",
      "Validation epoch 29 ; accuracy: 0.81; loss: 0.6069549918174744\n",
      "Training epoch 30 ; accuracy: 0.9857142857142858; loss: 0.08190654963254929\n",
      "Validation epoch 30 ; accuracy: 0.82; loss: 0.6124994158744812\n",
      "Training epoch 31 ; accuracy: 1.0; loss: 0.06970209628343582\n",
      "Validation epoch 31 ; accuracy: 0.82; loss: 0.6186979413032532\n",
      "Training epoch 32 ; accuracy: 1.0; loss: 0.06280910968780518\n",
      "Validation epoch 32 ; accuracy: 0.82; loss: 0.6250747442245483\n",
      "Training epoch 33 ; accuracy: 1.0; loss: 0.05892561376094818\n",
      "Validation epoch 33 ; accuracy: 0.82; loss: 0.6315549612045288\n",
      "Training epoch 34 ; accuracy: 0.9928571428571429; loss: 0.05428102985024452\n",
      "Validation epoch 34 ; accuracy: 0.82; loss: 0.6379781365394592\n",
      "Training epoch 35 ; accuracy: 0.9928571428571429; loss: 0.05133038014173508\n",
      "Validation epoch 35 ; accuracy: 0.82; loss: 0.6436745524406433\n",
      "Training epoch 36 ; accuracy: 1.0; loss: 0.041183650493621826\n",
      "Validation epoch 36 ; accuracy: 0.8166666666666667; loss: 0.6489502191543579\n",
      "Training epoch 37 ; accuracy: 1.0; loss: 0.03976104035973549\n",
      "Validation epoch 37 ; accuracy: 0.8166666666666667; loss: 0.6535054445266724\n",
      "Training epoch 38 ; accuracy: 1.0; loss: 0.035013020038604736\n",
      "Validation epoch 38 ; accuracy: 0.8166666666666667; loss: 0.6579275131225586\n",
      "Training epoch 39 ; accuracy: 1.0; loss: 0.0326833501458168\n",
      "Validation epoch 39 ; accuracy: 0.8166666666666667; loss: 0.6626107692718506\n",
      "Training epoch 40 ; accuracy: 1.0; loss: 0.028395190834999084\n",
      "Validation epoch 40 ; accuracy: 0.8166666666666667; loss: 0.666862964630127\n",
      "Training epoch 41 ; accuracy: 1.0; loss: 0.025729229673743248\n",
      "Validation epoch 41 ; accuracy: 0.8166666666666667; loss: 0.6711153984069824\n",
      "Training epoch 42 ; accuracy: 1.0; loss: 0.025706157088279724\n",
      "Validation epoch 42 ; accuracy: 0.82; loss: 0.6751059293746948\n",
      "Training epoch 43 ; accuracy: 1.0; loss: 0.02200809121131897\n",
      "Validation epoch 43 ; accuracy: 0.82; loss: 0.6791066527366638\n",
      "Training epoch 44 ; accuracy: 1.0; loss: 0.019945692270994186\n",
      "Validation epoch 44 ; accuracy: 0.82; loss: 0.6835044026374817\n",
      "Training epoch 45 ; accuracy: 1.0; loss: 0.020945528522133827\n",
      "Validation epoch 45 ; accuracy: 0.8233333333333334; loss: 0.6872577667236328\n",
      "Training epoch 46 ; accuracy: 1.0; loss: 0.017831968143582344\n",
      "Validation epoch 46 ; accuracy: 0.8233333333333334; loss: 0.691133975982666\n",
      "Training epoch 47 ; accuracy: 1.0; loss: 0.01708516851067543\n",
      "Validation epoch 47 ; accuracy: 0.8266666666666667; loss: 0.6955181360244751\n",
      "Training epoch 48 ; accuracy: 1.0; loss: 0.014943799003958702\n",
      "Validation epoch 48 ; accuracy: 0.8266666666666667; loss: 0.7000142335891724\n",
      "Training epoch 49 ; accuracy: 1.0; loss: 0.0155528848990798\n",
      "Validation epoch 49 ; accuracy: 0.8266666666666667; loss: 0.7043289542198181\n",
      "Training epoch 50 ; accuracy: 1.0; loss: 0.013166618533432484\n",
      "Validation epoch 50 ; accuracy: 0.8266666666666667; loss: 0.7083677053451538\n",
      "Training epoch 51 ; accuracy: 1.0; loss: 0.013357937335968018\n",
      "Validation epoch 51 ; accuracy: 0.83; loss: 0.7119952440261841\n",
      "Training epoch 52 ; accuracy: 1.0; loss: 0.012252294458448887\n",
      "Validation epoch 52 ; accuracy: 0.8266666666666667; loss: 0.7154963612556458\n",
      "Training epoch 53 ; accuracy: 1.0; loss: 0.011636550538241863\n",
      "Validation epoch 53 ; accuracy: 0.8266666666666667; loss: 0.7187714576721191\n",
      "Training epoch 54 ; accuracy: 1.0; loss: 0.010890753008425236\n",
      "Validation epoch 54 ; accuracy: 0.8266666666666667; loss: 0.7220776677131653\n",
      "Training epoch 55 ; accuracy: 1.0; loss: 0.00968613289296627\n",
      "Validation epoch 55 ; accuracy: 0.8266666666666667; loss: 0.7252092361450195\n",
      "Training epoch 56 ; accuracy: 1.0; loss: 0.010464952327311039\n",
      "Validation epoch 56 ; accuracy: 0.8233333333333334; loss: 0.7287672162055969\n",
      "Training epoch 57 ; accuracy: 1.0; loss: 0.00982480775564909\n",
      "Validation epoch 57 ; accuracy: 0.8233333333333334; loss: 0.7322533130645752\n",
      "Training epoch 58 ; accuracy: 1.0; loss: 0.009477977640926838\n",
      "Validation epoch 58 ; accuracy: 0.8233333333333334; loss: 0.7356176376342773\n",
      "Training epoch 59 ; accuracy: 1.0; loss: 0.008189080283045769\n",
      "Validation epoch 59 ; accuracy: 0.8233333333333334; loss: 0.7386628985404968\n",
      "Training epoch 60 ; accuracy: 1.0; loss: 0.008440801873803139\n",
      "Validation epoch 60 ; accuracy: 0.8233333333333334; loss: 0.7414035797119141\n",
      "Training epoch 61 ; accuracy: 1.0; loss: 0.008079923689365387\n",
      "Validation epoch 61 ; accuracy: 0.8233333333333334; loss: 0.7439473271369934\n",
      "Training epoch 62 ; accuracy: 1.0; loss: 0.007180920802056789\n",
      "Validation epoch 62 ; accuracy: 0.8233333333333334; loss: 0.7465465068817139\n",
      "Training epoch 63 ; accuracy: 1.0; loss: 0.007289663422852755\n",
      "Validation epoch 63 ; accuracy: 0.82; loss: 0.7491365671157837\n",
      "Training epoch 64 ; accuracy: 1.0; loss: 0.006283091846853495\n",
      "Validation epoch 64 ; accuracy: 0.82; loss: 0.7515771389007568\n",
      "Training epoch 65 ; accuracy: 1.0; loss: 0.006285283248871565\n",
      "Validation epoch 65 ; accuracy: 0.82; loss: 0.7539923191070557\n",
      "Training epoch 66 ; accuracy: 1.0; loss: 0.006369002163410187\n",
      "Validation epoch 66 ; accuracy: 0.82; loss: 0.7562548518180847\n",
      "Training epoch 67 ; accuracy: 1.0; loss: 0.005959987174719572\n",
      "Validation epoch 67 ; accuracy: 0.82; loss: 0.7586027979850769\n",
      "Training epoch 68 ; accuracy: 1.0; loss: 0.006076526362448931\n",
      "Validation epoch 68 ; accuracy: 0.82; loss: 0.7609484791755676\n",
      "Training epoch 69 ; accuracy: 1.0; loss: 0.0053387777879834175\n",
      "Validation epoch 69 ; accuracy: 0.82; loss: 0.7634260654449463\n",
      "Training epoch 70 ; accuracy: 1.0; loss: 0.005004762206226587\n",
      "Validation epoch 70 ; accuracy: 0.82; loss: 0.7659511566162109\n",
      "Training epoch 71 ; accuracy: 1.0; loss: 0.005436141975224018\n",
      "Validation epoch 71 ; accuracy: 0.82; loss: 0.76824951171875\n",
      "Training epoch 72 ; accuracy: 1.0; loss: 0.005147494375705719\n",
      "Validation epoch 72 ; accuracy: 0.82; loss: 0.7703445553779602\n",
      "Training epoch 73 ; accuracy: 1.0; loss: 0.004812334198504686\n",
      "Validation epoch 73 ; accuracy: 0.8233333333333334; loss: 0.7720824480056763\n",
      "Training epoch 74 ; accuracy: 1.0; loss: 0.0049729798920452595\n",
      "Validation epoch 74 ; accuracy: 0.8233333333333334; loss: 0.773526668548584\n",
      "Training epoch 75 ; accuracy: 1.0; loss: 0.004815526306629181\n",
      "Validation epoch 75 ; accuracy: 0.8233333333333334; loss: 0.7745664119720459\n",
      "Training epoch 76 ; accuracy: 1.0; loss: 0.004577102605253458\n",
      "Validation epoch 76 ; accuracy: 0.8233333333333334; loss: 0.77538001537323\n",
      "Training epoch 77 ; accuracy: 1.0; loss: 0.004482627846300602\n",
      "Validation epoch 77 ; accuracy: 0.8233333333333334; loss: 0.77610844373703\n",
      "Training epoch 78 ; accuracy: 1.0; loss: 0.004601895343512297\n",
      "Validation epoch 78 ; accuracy: 0.8233333333333334; loss: 0.77663654088974\n",
      "Training epoch 79 ; accuracy: 1.0; loss: 0.004189722239971161\n",
      "Validation epoch 79 ; accuracy: 0.8233333333333334; loss: 0.777195394039154\n",
      "Training epoch 80 ; accuracy: 1.0; loss: 0.004157322458922863\n",
      "Validation epoch 80 ; accuracy: 0.8233333333333334; loss: 0.7779214382171631\n",
      "Training epoch 81 ; accuracy: 1.0; loss: 0.003968382719904184\n",
      "Validation epoch 81 ; accuracy: 0.8233333333333334; loss: 0.7788316011428833\n",
      "Training epoch 82 ; accuracy: 1.0; loss: 0.0040413569658994675\n",
      "Validation epoch 82 ; accuracy: 0.8233333333333334; loss: 0.7797195911407471\n",
      "Training epoch 83 ; accuracy: 1.0; loss: 0.0037596384063363075\n",
      "Validation epoch 83 ; accuracy: 0.8233333333333334; loss: 0.7806826233863831\n",
      "Training epoch 84 ; accuracy: 1.0; loss: 0.00353352096863091\n",
      "Validation epoch 84 ; accuracy: 0.8233333333333334; loss: 0.7815934419631958\n",
      "Training epoch 85 ; accuracy: 1.0; loss: 0.0037801938597112894\n",
      "Validation epoch 85 ; accuracy: 0.8233333333333334; loss: 0.7825256586074829\n",
      "Training epoch 86 ; accuracy: 1.0; loss: 0.0037127677351236343\n",
      "Validation epoch 86 ; accuracy: 0.8233333333333334; loss: 0.7837439775466919\n",
      "Training epoch 87 ; accuracy: 1.0; loss: 0.0035142607521265745\n",
      "Validation epoch 87 ; accuracy: 0.8233333333333334; loss: 0.7850610613822937\n",
      "Training epoch 88 ; accuracy: 1.0; loss: 0.0035279132425785065\n",
      "Validation epoch 88 ; accuracy: 0.8233333333333334; loss: 0.7863317131996155\n",
      "Training epoch 89 ; accuracy: 1.0; loss: 0.003613456152379513\n",
      "Validation epoch 89 ; accuracy: 0.8233333333333334; loss: 0.7878254055976868\n",
      "Training epoch 90 ; accuracy: 1.0; loss: 0.0036803705152124166\n",
      "Validation epoch 90 ; accuracy: 0.8233333333333334; loss: 0.7894116044044495\n",
      "Training epoch 91 ; accuracy: 1.0; loss: 0.0033592109102755785\n",
      "Validation epoch 91 ; accuracy: 0.8233333333333334; loss: 0.7908744812011719\n",
      "Training epoch 92 ; accuracy: 1.0; loss: 0.0033518075942993164\n",
      "Validation epoch 92 ; accuracy: 0.82; loss: 0.7923003435134888\n",
      "Training epoch 93 ; accuracy: 1.0; loss: 0.0030775379855185747\n",
      "Validation epoch 93 ; accuracy: 0.82; loss: 0.793487548828125\n",
      "Training epoch 94 ; accuracy: 1.0; loss: 0.003338378621265292\n",
      "Validation epoch 94 ; accuracy: 0.82; loss: 0.7947774529457092\n",
      "Training epoch 95 ; accuracy: 1.0; loss: 0.0029439637437462807\n",
      "Validation epoch 95 ; accuracy: 0.82; loss: 0.7960285544395447\n",
      "Training epoch 96 ; accuracy: 1.0; loss: 0.0029871107544749975\n",
      "Validation epoch 96 ; accuracy: 0.82; loss: 0.7972619533538818\n",
      "Training epoch 97 ; accuracy: 1.0; loss: 0.0031582675874233246\n",
      "Validation epoch 97 ; accuracy: 0.82; loss: 0.7986300587654114\n",
      "Training epoch 98 ; accuracy: 1.0; loss: 0.0029012239538133144\n",
      "Validation epoch 98 ; accuracy: 0.82; loss: 0.8000752925872803\n",
      "Training epoch 99 ; accuracy: 1.0; loss: 0.002813872415572405\n",
      "Validation epoch 99 ; accuracy: 0.82; loss: 0.8012741208076477\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "epochs=100\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01)\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "train_accuracy=[]\n",
    "val_accuracy=[]\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_labels=labels[idx_train]\n",
    "    val_labels=labels[idx_val]\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj)\n",
    "    train_loss=F.nll_loss(output[idx_train],train_labels)\n",
    "    train_losses.append(train_loss)\n",
    "    t_a=accuracy(output[idx_train],train_labels)\n",
    "    train_accuracy.append(t_a)\n",
    "    print(f\"Training epoch {epoch} ; accuracy: {accuracy(output[idx_train],train_labels)}; loss: {train_loss.item()}\")\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    val_loss=F.nll_loss(output[idx_val],val_labels)\n",
    "    val_losses.append(val_loss)\n",
    "    v_a=accuracy(output[idx_val],val_labels)\n",
    "    val_accuracy.append(v_a)\n",
    "    print(f\"Validation epoch {epoch} ; accuracy: {accuracy(output[idx_val],val_labels)}; loss: {val_loss.item()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangjunekoo/anaconda3/envs/pytorch/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "/home/kangjunekoo/anaconda3/envs/pytorch/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses_float=[float(train_loss.cpu().detach().numpy()) for train_loss in train_losses]\n",
    "train_loss_indices=[i for i, l in enumerate(train_losses_float)]\n",
    "plt=sns.lineplot(train_loss_indices,train_losses_float)\n",
    "val_losses_float=[float(val_loss.cpu().detach().numpy()) for val_loss in val_losses]\n",
    "val_loss_indices=[i for i, l in enumerate(val_losses_float)]\n",
    "plt=sns.lineplot(val_loss_indices,val_losses_float,color='r')\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_a = t_a.cpu().detach().numpy()\n",
    "v_a = v_a.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangjunekoo/anaconda3/envs/pytorch/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "/home/kangjunekoo/anaconda3/envs/pytorch/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_accuracy_float=[float(t_a.cpu().detach().numpy()) for t_a in train_accuracy]\n",
    "t_a_indices=[i for i, l in enumerate(train_accuracy_float)]\n",
    "plt=sns.lineplot(t_a_indices,train_accuracy_float,color='green')\n",
    "\n",
    "val_accuracy_float=[float(v_a.cpu().detach().numpy()) for v_a in val_accuracy]\n",
    "v_a_indices=[i for i, l in enumerate(val_accuracy_float)]\n",
    "plt=sns.lineplot(v_a_indices,val_accuracy_float,color='black')\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ; accuracy: 0.669; loss: 0.9876585006713867\n"
     ]
    }
   ],
   "source": [
    "test_losses=[]\n",
    "model.eval()\n",
    "test_labels=labels[idx_test]\n",
    "output = model(features, adj)\n",
    "loss=F.nll_loss(output[idx_test],test_labels)\n",
    "test_losses.append(loss)\n",
    "print(f\"Test set ; accuracy: {accuracy(output[idx_test],test_labels)}; loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sample = 500\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "print(model(features, adj).shape)\n",
    "pred = model(features, adj)\n",
    "sns.barplot(x=np.array(range(7)), y=pred[sample].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_idx_test=output[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.651942</td>\n",
       "      <td>-3.651942</td>\n",
       "      <td>-0.170443</td>\n",
       "      <td>-3.651942</td>\n",
       "      <td>-3.651942</td>\n",
       "      <td>-3.611710</td>\n",
       "      <td>-3.651942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.826761</td>\n",
       "      <td>-4.853640</td>\n",
       "      <td>-3.768618</td>\n",
       "      <td>-4.721383</td>\n",
       "      <td>-0.067527</td>\n",
       "      <td>-4.853640</td>\n",
       "      <td>-4.635790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.502378</td>\n",
       "      <td>-7.502378</td>\n",
       "      <td>-0.020207</td>\n",
       "      <td>-7.502378</td>\n",
       "      <td>-4.087018</td>\n",
       "      <td>-6.900223</td>\n",
       "      <td>-7.502378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.499911</td>\n",
       "      <td>-5.499911</td>\n",
       "      <td>-5.303761</td>\n",
       "      <td>-5.376230</td>\n",
       "      <td>-0.026949</td>\n",
       "      <td>-5.499911</td>\n",
       "      <td>-5.353931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.788297</td>\n",
       "      <td>-4.842309</td>\n",
       "      <td>-0.126655</td>\n",
       "      <td>-4.842309</td>\n",
       "      <td>-3.616222</td>\n",
       "      <td>-2.847855</td>\n",
       "      <td>-4.604618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-2.014552</td>\n",
       "      <td>-2.123931</td>\n",
       "      <td>-1.524173</td>\n",
       "      <td>-2.123931</td>\n",
       "      <td>-2.123931</td>\n",
       "      <td>-1.768575</td>\n",
       "      <td>-2.123931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-8.949731</td>\n",
       "      <td>-10.944406</td>\n",
       "      <td>-10.944406</td>\n",
       "      <td>-10.944406</td>\n",
       "      <td>-9.862147</td>\n",
       "      <td>-10.944406</td>\n",
       "      <td>-0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-5.510885</td>\n",
       "      <td>-6.888665</td>\n",
       "      <td>-5.485894</td>\n",
       "      <td>-6.888665</td>\n",
       "      <td>-6.215913</td>\n",
       "      <td>-6.559607</td>\n",
       "      <td>-0.013734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-1.251792</td>\n",
       "      <td>-3.885541</td>\n",
       "      <td>-2.580560</td>\n",
       "      <td>-3.473157</td>\n",
       "      <td>-3.574414</td>\n",
       "      <td>-3.669913</td>\n",
       "      <td>-0.628839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-7.454676</td>\n",
       "      <td>-8.172600</td>\n",
       "      <td>-8.172600</td>\n",
       "      <td>-8.172600</td>\n",
       "      <td>-0.004029</td>\n",
       "      <td>-6.188050</td>\n",
       "      <td>-7.520314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3         4          5         6\n",
       "0   -3.651942  -3.651942  -0.170443  -3.651942 -3.651942  -3.611710 -3.651942\n",
       "1   -4.826761  -4.853640  -3.768618  -4.721383 -0.067527  -4.853640 -4.635790\n",
       "2   -7.502378  -7.502378  -0.020207  -7.502378 -4.087018  -6.900223 -7.502378\n",
       "3   -5.499911  -5.499911  -5.303761  -5.376230 -0.026949  -5.499911 -5.353931\n",
       "4   -4.788297  -4.842309  -0.126655  -4.842309 -3.616222  -2.847855 -4.604618\n",
       "..        ...        ...        ...        ...       ...        ...       ...\n",
       "995 -2.014552  -2.123931  -1.524173  -2.123931 -2.123931  -1.768575 -2.123931\n",
       "996 -8.949731 -10.944406 -10.944406 -10.944406 -9.862147 -10.944406 -0.000253\n",
       "997 -5.510885  -6.888665  -5.485894  -6.888665 -6.215913  -6.559607 -0.013734\n",
       "998 -1.251792  -3.885541  -2.580560  -3.473157 -3.574414  -3.669913 -0.628839\n",
       "999 -7.454676  -8.172600  -8.172600  -8.172600 -0.004029  -6.188050 -7.520314\n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_idx_test=pd.DataFrame(output_idx_test.detach().numpy())\n",
    "df_output_idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
       "0    2    4    2    4    4    4    2    5    5    0  ...    4    5    5    4   \n",
       "\n",
       "   994  995  996  997  998  999  \n",
       "0    4    1    6    6    6    4  \n",
       "\n",
       "[1 rows x 1000 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_labels=pd.DataFrame(test_labels.numpy())\n",
    "print(type(df_test_labels))\n",
    "df_test_labels.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "366252978e52bb2df929d3934aeb3ff29dfa67e45e575a59a0b0194f7beef5a9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
