{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will write a matrix factorization model in pytorch to solve a recommendation problem. Then we will write a more general neural model for the same problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MovieLens dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100004 ratings and 1296 tag applications across 9125 movies. https://grouplens.org/datasets/movielens/. To get the data:\n",
    "\n",
    "`wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('ml-25m/genome-scores.csv'),\n",
       " PosixPath('ml-25m/movies.csv'),\n",
       " PosixPath('ml-25m/genome-tags.csv'),\n",
       " PosixPath('ml-25m/tags.csv'),\n",
       " PosixPath('ml-25m/README.txt'),\n",
       " PosixPath('ml-25m/links.csv'),\n",
       " PosixPath('ml-25m/original collaborative-filtering-nn.ipynb'),\n",
       " PosixPath('ml-25m/ratings.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = Path(\"ml-25m/\")\n",
    "#PATH = Path(\"/data2/yinterian/ml-latest-small/\")\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(PATH/\"ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147880044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147868828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147878820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      296     5.0  1147880044\n",
       "1       1      306     3.5  1147868817\n",
       "2       1      307     5.0  1147868828\n",
       "3       1      665     5.0  1147878820\n",
       "4       1      899     3.5  1147868510"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding data\n",
    "We enconde the data to have contiguous ids for users and movies. You can think about this as a categorical encoding of our two categorical variables userId and movieId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and validation before encoding\n",
    "np.random.seed(3)\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train = data[msk].copy()\n",
    "val = data[~msk].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a handy function modified from fast.ai\n",
    "def proc_col(col, train_col=None):\n",
    "    \"\"\"Encodes a pandas column with continous ids. \n",
    "    \"\"\"\n",
    "    if train_col is not None:\n",
    "        uniq = train_col.unique()\n",
    "    else:\n",
    "        uniq = col.unique()\n",
    "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
    "    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df, train=None):\n",
    "    \"\"\" Encodes rating data with continous user and movie ids. \n",
    "    If train is provided, encodes df with the same encoding as train.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for col_name in [\"userId\", \"movieId\"]:\n",
    "        train_col = None\n",
    "        if train is not None:\n",
    "            train_col = train[col_name]\n",
    "        _,col,_ = proc_col(df[col_name], train_col)\n",
    "        df[col_name] = col\n",
    "        df = df[df[col_name] >= 0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the train and validation data\n",
    "df_train = encode_data(train)\n",
    "df_val = encode_data(val, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangjunekoo/anaconda3/envs/Pytorch2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162541 56642\n"
     ]
    }
   ],
   "source": [
    "num_users = len(df_train.userId.unique())\n",
    "num_items = len(df_train.movieId.unique())\n",
    "print(num_users, num_items) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global train_losses\n",
    "train_losses=[]\n",
    "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        global users,items,ratings\n",
    "        users = torch.LongTensor(df_train.userId.values) # .cuda()\n",
    "        items = torch.LongTensor(df_train.movieId.values) #.cuda()\n",
    "        ratings = torch.FloatTensor(df_train.rating.values) #.cuda()\n",
    "        if unsqueeze:\n",
    "            ratings = ratings.unsqueeze(1)\n",
    "        y_hat = model(users, items)\n",
    "        loss = F.mse_loss(y_hat, ratings)\n",
    "        train_losses.append(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"epochs : \",i) \n",
    "        print(\"train loss %.3f \" % loss.item()) \n",
    "        test_loss(model, unsqueeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19999967])\n",
      "torch.Size([19999967, 1])\n"
     ]
    }
   ],
   "source": [
    "# Here is what unsqueeze does\n",
    "ratings = torch.FloatTensor(df_train.rating.values)\n",
    "print(ratings.shape)\n",
    "ratings = ratings.unsqueeze(1) # .cuda()\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "global val_losses\n",
    "val_losses=[]\n",
    "def test_loss(model, unsqueeze=False):\n",
    "    model.eval()\n",
    "    global users,items,ratings,y_hat\n",
    "    users = torch.LongTensor(df_val.userId.values) #.cuda()\n",
    "    items = torch.LongTensor(df_val.movieId.values) #.cuda()\n",
    "    ratings = torch.FloatTensor(df_val.rating.values) #.cuda()\n",
    "    if unsqueeze:\n",
    "        ratings = ratings.unsqueeze(1)\n",
    "    y_hat = model(users, items)\n",
    "    global df_users,df_items,df_y_hat,df_ratings\n",
    "    df_users=pd.DataFrame(users.numpy())\n",
    "    df_items=pd.DataFrame(items.numpy())\n",
    "    df_y_hat=pd.DataFrame(y_hat.detach().numpy())\n",
    "    df_ratings=pd.DataFrame(ratings.numpy())\n",
    "\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "    val_losses.append(loss)\n",
    "    print(\"validation loss %.3f \" % loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note here there is no matrix multiplication, we could potentially make the embeddings of different sizes.\n",
    "# Here we could get better results by keep playing with regularization.\n",
    "    \n",
    "class CollabFNet(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100, n_hidden=10):\n",
    "        super(CollabFNet, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.lin1 = nn.Linear(emb_size*2, n_hidden)\n",
    "        self.lin2 = nn.Linear(n_hidden, 1)\n",
    "        self.drop1 = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        global U,V\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        x = F.relu(torch.cat([U, V], dim=1))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CollabFNet(num_users, num_items, emb_size=100) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs :  0\n",
      "train loss 13.962 \n",
      "validation loss 3.316 \n",
      "epochs :  1\n",
      "train loss 3.320 \n",
      "validation loss 1.293 \n",
      "epochs :  2\n",
      "train loss 1.294 \n",
      "validation loss 1.886 \n",
      "epochs :  3\n",
      "train loss 1.885 \n",
      "validation loss 1.866 \n",
      "epochs :  4\n",
      "train loss 1.864 \n",
      "validation loss 1.213 \n",
      "epochs :  5\n",
      "train loss 1.212 \n",
      "validation loss 1.243 \n",
      "epochs :  6\n",
      "train loss 1.243 \n",
      "validation loss 1.478 \n",
      "epochs :  7\n",
      "train loss 1.477 \n",
      "validation loss 1.127 \n",
      "epochs :  8\n",
      "train loss 1.125 \n",
      "validation loss 0.988 \n",
      "epochs :  9\n",
      "train loss 0.985 \n",
      "validation loss 1.161 \n",
      "epochs :  10\n",
      "train loss 1.156 \n",
      "validation loss 1.181 \n",
      "epochs :  11\n",
      "train loss 1.176 \n",
      "validation loss 0.991 \n",
      "epochs :  12\n",
      "train loss 0.986 \n",
      "validation loss 0.891 \n",
      "epochs :  13\n",
      "train loss 0.886 \n",
      "validation loss 1.005 \n",
      "epochs :  14\n",
      "train loss 1.000 \n",
      "validation loss 1.022 \n",
      "epochs :  15\n",
      "train loss 1.017 \n",
      "validation loss 0.898 \n",
      "epochs :  16\n",
      "train loss 0.892 \n",
      "validation loss 0.884 \n",
      "epochs :  17\n",
      "train loss 0.877 \n",
      "validation loss 0.963 \n",
      "epochs :  18\n",
      "train loss 0.956 \n",
      "validation loss 0.966 \n",
      "epochs :  19\n",
      "train loss 0.959 \n",
      "validation loss 0.889 \n",
      "epochs :  20\n",
      "train loss 0.882 \n",
      "validation loss 0.862 \n",
      "epochs :  21\n",
      "train loss 0.854 \n",
      "validation loss 0.906 \n",
      "epochs :  22\n",
      "train loss 0.898 \n",
      "validation loss 0.901 \n",
      "epochs :  23\n",
      "train loss 0.894 \n",
      "validation loss 0.851 \n",
      "epochs :  24\n",
      "train loss 0.843 \n",
      "validation loss 0.851 \n",
      "epochs :  25\n",
      "train loss 0.843 \n",
      "validation loss 0.881 \n",
      "epochs :  26\n",
      "train loss 0.873 \n",
      "validation loss 0.873 \n",
      "epochs :  27\n",
      "train loss 0.865 \n",
      "validation loss 0.838 \n",
      "epochs :  28\n",
      "train loss 0.830 \n",
      "validation loss 0.834 \n",
      "epochs :  29\n",
      "train loss 0.826 \n",
      "validation loss 0.850 \n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=30, lr=0.05, wd=1e-6, unsqueeze=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangjunekoo/anaconda3/envs/Pytorch2/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "/home/kangjunekoo/anaconda3/envs/Pytorch2/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "train_losses_float=[float(train_loss.cpu().detach().numpy()) for train_loss in train_losses]\n",
    "train_loss_indices=[i for i, l in enumerate(train_losses_float)]\n",
    "plt=sns.lineplot(train_loss_indices,train_losses_float)\n",
    "val_losses_float=[float(val_loss.cpu().detach().numpy()) for val_loss in val_losses]\n",
    "val_loss_indices=[i for i, l in enumerate(val_losses_float)]\n",
    "plt=sns.lineplot(val_loss_indices,val_losses_float,color='r')\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4997311</th>\n",
       "      <th>4997312</th>\n",
       "      <th>4997313</th>\n",
       "      <th>4997314</th>\n",
       "      <th>4997315</th>\n",
       "      <th>4997316</th>\n",
       "      <th>4997317</th>\n",
       "      <th>4997318</th>\n",
       "      <th>4997319</th>\n",
       "      <th>4997320</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>162540</td>\n",
       "      <td>162540</td>\n",
       "      <td>162540</td>\n",
       "      <td>162540</td>\n",
       "      <td>162540</td>\n",
       "      <td>162540</td>\n",
       "      <td>162540</td>\n",
       "      <td>162540</td>\n",
       "      <td>162540</td>\n",
       "      <td>162540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4997321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0        1        2        3        4        5        6        7        \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   8        9        ...  4997311  4997312  4997313  4997314  4997315  \\\n",
       "0        1        1  ...   162540   162540   162540   162540   162540   \n",
       "\n",
       "   4997316  4997317  4997318  4997319  4997320  \n",
       "0   162540   162540   162540   162540   162540  \n",
       "\n",
       "[1 rows x 4997321 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4997311</th>\n",
       "      <th>4997312</th>\n",
       "      <th>4997313</th>\n",
       "      <th>4997314</th>\n",
       "      <th>4997315</th>\n",
       "      <th>4997316</th>\n",
       "      <th>4997317</th>\n",
       "      <th>4997318</th>\n",
       "      <th>4997319</th>\n",
       "      <th>4997320</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>1119</td>\n",
       "      <td>1567</td>\n",
       "      <td>3552</td>\n",
       "      <td>10649</td>\n",
       "      <td>8904</td>\n",
       "      <td>4143</td>\n",
       "      <td>18293</td>\n",
       "      <td>801</td>\n",
       "      <td>811</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>3465</td>\n",
       "      <td>356</td>\n",
       "      <td>364</td>\n",
       "      <td>1494</td>\n",
       "      <td>196</td>\n",
       "      <td>1683</td>\n",
       "      <td>1593</td>\n",
       "      <td>717</td>\n",
       "      <td>6542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4997321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0        1        2        3        4        5        6        7        \\\n",
       "0     2018     1119     1567     3552    10649     8904     4143    18293   \n",
       "\n",
       "   8        9        ...  4997311  4997312  4997313  4997314  4997315  \\\n",
       "0      801      811  ...      164     3465      356      364     1494   \n",
       "\n",
       "   4997316  4997317  4997318  4997319  4997320  \n",
       "0      196     1683     1593      717     6542  \n",
       "\n",
       "[1 rows x 4997321 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_items.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4997311</th>\n",
       "      <th>4997312</th>\n",
       "      <th>4997313</th>\n",
       "      <th>4997314</th>\n",
       "      <th>4997315</th>\n",
       "      <th>4997316</th>\n",
       "      <th>4997317</th>\n",
       "      <th>4997318</th>\n",
       "      <th>4997319</th>\n",
       "      <th>4997320</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.06573</td>\n",
       "      <td>3.241074</td>\n",
       "      <td>4.250451</td>\n",
       "      <td>4.027228</td>\n",
       "      <td>3.029732</td>\n",
       "      <td>3.059823</td>\n",
       "      <td>3.104952</td>\n",
       "      <td>2.813874</td>\n",
       "      <td>3.903775</td>\n",
       "      <td>3.605015</td>\n",
       "      <td>...</td>\n",
       "      <td>4.130039</td>\n",
       "      <td>3.800296</td>\n",
       "      <td>2.871465</td>\n",
       "      <td>3.12014</td>\n",
       "      <td>3.771618</td>\n",
       "      <td>3.835198</td>\n",
       "      <td>3.549557</td>\n",
       "      <td>4.048035</td>\n",
       "      <td>3.70741</td>\n",
       "      <td>1.80628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4997321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6        \\\n",
       "0  4.06573  3.241074  4.250451  4.027228  3.029732  3.059823  3.104952   \n",
       "\n",
       "    7         8         9        ...   4997311   4997312   4997313  4997314  \\\n",
       "0  2.813874  3.903775  3.605015  ...  4.130039  3.800296  2.871465  3.12014   \n",
       "\n",
       "    4997315   4997316   4997317   4997318  4997319  4997320  \n",
       "0  3.771618  3.835198  3.549557  4.048035  3.70741  1.80628  \n",
       "\n",
       "[1 rows x 4997321 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_hat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4997311</th>\n",
       "      <th>4997312</th>\n",
       "      <th>4997313</th>\n",
       "      <th>4997314</th>\n",
       "      <th>4997315</th>\n",
       "      <th>4997316</th>\n",
       "      <th>4997317</th>\n",
       "      <th>4997318</th>\n",
       "      <th>4997319</th>\n",
       "      <th>4997320</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4997321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0        1        2        3        4        5        6        7        \\\n",
       "0      3.5      4.0      4.5      4.0      2.0      5.0      2.0      3.5   \n",
       "\n",
       "   8        9        ...  4997311  4997312  4997313  4997314  4997315  \\\n",
       "0      4.5      3.5  ...      5.0      4.5      3.0      2.0      4.5   \n",
       "\n",
       "   4997316  4997317  4997318  4997319  4997320  \n",
       "0      4.0      4.5      4.5      4.5      2.0  \n",
       "\n",
       "[1 rows x 4997321 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
